\documentclass{ExpressiveResume}

% ----- Resume -----
\begin{document}

% ----- Name + Contact Information -----
\resumeheader[
    % firstname=Sai Teja,
    middleinitial=Ram Polisetti,
    % lastname=Ram Polisetti,
    email=rampolisettius@gmail.com,
    phone=716-256-7258,
    linkedin=ram-polisetti,
    github=ram-polisetti,
    city=Seattle,
    state=WA,
    fixobjectivespacing=true
]

\objective{Results-driven Data Engineer with expertise in designing,
    building, and maintaining large-scale data systems. Skilled in data
    pipeline development, data processing, and data storage solutions.
    Proficient in a range of technologies, including Apache Spark, Hadoop, NoSQL databases, and cloud computing platforms.}


% {
%     Highly motivated and detail-oriented data analyst with
%     experience in driving business growth and improvement through data-driven insights.
%     Proven track record of analyzing complex data systems and processes to
%     identify opportunities for cost savings and efficiency improvements.
%     Skilled in data analysis, machine learning, and data visualization, with
%     a strong background in operations optimization and business processes. Possesses excellent communication and problem-solving
%     skills, with the ability to work effectively in fast-paced environments.
% }

% ----- Education -----
\section{Education}

\experience{Master of Science}{Data Science}{Sept 2022}{Jan 2024}{
    \noindent State University of New York (UB), Buffalo, NY
}

% ------ Skills -----
\section{Skills}
\skills{Python, R, Java, Scala, SQL, Spark, MongoDB, PostgreSQL, MySQL,
    AWS, Azure, databricks, Apache Airflow, Kafka, Data Storage
    (Redshift, BigQuery, Snowflake), Data Security, Data
    Governance, Docker,
    Kubernetes, Agile methodologies, Git, CI/CD Practices (Jenkins), Model
    Evaluation, Model Deployment, Data Mining.

}

% ----- Work Experience -----
\section{Work Experience}

\experience{JerseyStem, New Jersey}{Data Analyst}{Mar 2024}{Present}{
    \achievement{Designed and implemented data pipelines to ingest, process, and store large datasets, resulting in a \textbf{25\% reduction} in data processing time and a \textbf{15\% increase} in data quality.}
    \achievement{Developed and deployed data visualizations using \tech{Tableau} to communicate insights to stakeholders, achieving a \textbf{90\% adoption rate} among business users and a \textbf{20\% increase} in data-driven decision-making.}
}
\experience{Amazon Inc., Hyderabad, India}{Transportation Specialist}{Nov 2020}{Jul 2022}{
    \achievement{Built and maintained large-scale data systems to analyze and optimize transportation operations, resulting in a \textbf{15\% decrease} in transportation costs and a \textbf{10\% improvement} in on-time delivery rates.}
    \achievement{Developed and implemented data integration solutions using \tech{SQL} and \tech{Excel} to combine data from multiple sources, achieving a \textbf{12\% cost savings} and a \textbf{10\% increase} in capacity utilization.}
    \achievement{Collaborated with cross-functional teams to design and implement data-driven solutions, resulting in a \textbf{15\% increase} in productivity and a \textbf{25\% reduction} in manual errors.}
}
\experience{National Instruments}{Analyst Intern}{Nov 2018}{Feb 2020}{
    \achievement{Built predictive models using statistical and machine learning techniques, achieving a \textbf{90\% accuracy rate} in forecasting product demand and a \textbf{15\% reduction} in inventory costs. Developed and deployed predictive models using \tech{Python} and \tech{SQL}.}
    \achievement{Identified opportunities for process improvements and cost savings, resulting in a \textbf{10\% reduction} in production costs and a \textbf{5\% increase} in product quality.}
    \achievement{Enhanced dashboards and reports to track key performance indicators (KPIs) and metrics, achieving a \textbf{95\% completion rate} for reports.}
}


% ----- Technical Projects -----

\section{Technical Projects}

\project{Python, Apache Spark, PostgreSQL, Tableau} {E-Commerce Sales Data Pipeline}{}{}{
    \achievement{Captained the design and implementation of a comprehensive data pipeline for automating the ingestion, processing, and storage of e-commerce sales data across multiple sources.}
    \achievement{Leveraged \tech{Apache Spark} for high-efficiency data processing, achieving a \textbf{20\% improvement} in processing speed, and developed a sophisticated \tech{PostgreSQL} database schema for optimal data storage and retrieval.}
    \achievement{Utilized \tech{Tableau} to create dynamic, interactive dashboards providing deep insights into sales trends, customer behavior, and inventory management.}
}

\project{Kafka, NLTK, Scikit-learn, MongoDB, PowerBI}{Real-Time Social Media Trend Analysis Platform}{}{}{
    \achievement{Developed a platform for real-time analysis of social media data, applying \tech{Kafka} for efficient stream processing, \tech{NLTK} and \tech{Scikit-learn} for sentiment analysis, achieving \textbf{85\% accuracy} in sentiment classification.}
    \achievement{Implemented \tech{MongoDB} for scalable data storage, allowing for rapid data retrieval.}
    \achievement{Designed and deployed \tech{Power BI} dashboards for real-time visualization of social media trends and sentiments, enabling stakeholders to make informed decisions based on current public opinion.}
}

% \project{Machine Learning, Ensemble Methods, Deep Learning, Apache Spark, AWS}{Fraud Detection System}{}{}{
%     \achievement{Developed and deployed an advanced fraud detection system utilizing \textbf{ensemble methods}, achieving \textbf{92\% accuracy} on test data and demonstrating practical experience in cloud-based machine learning operations.}
%     \achievement{Designed and implemented robust data pipelines using \tech{Apache Spark} to efficiently process and analyze datasets, enabling scalable and reliable data processing.}
%     \achievement{Applied \textbf{end-to-end machine learning workflow}, from data preprocessing to model evaluation and deployment, ensuring a comprehensive and structured approach to machine learning operations.}
% }

% \project{E-Commerce Sales Data Pipeline}{Data Engineer}{}{}{
%     \achievement{Captained the design and implementation of a comprehensive data pipeline for automating the ingestion, processing, and storage of e-commerce sales data across multiple sources, utilizing \tech{Python}, \tech{Apache Spark}, \tech{PostgreSQL}, and \tech{Tableau}.}
%     \achievement{Leveraged \tech{Apache Spark} for high-efficiency data processing, achieving a 20\% improvement in processing speed, and developed a sophisticated \tech{PostgreSQL} database schema for optimal data storage and retrieval.}
%     \achievement{Harnessed \tech{Tableau} to create dynamic, interactive dashboards providing deep insights into sales trends, customer behavior, and inventory management.}
% }


% \project{Python, Plotly, SQL, Monte Carlo Simulation}{Strategic Route Optimization and Cost Minimization}{}{}{
%     \achievement{Engineered a network optimization strategy using \tech{NetworkX}, delineating 30 critical plant-port connections, thereby enhancing logistical efficiency and reducing route costs.}
%     \achievement{Created a constraint-based allocation model for 50+ products and 30 customers, achieving a 100\% adherence to Vendor Managed Inventory (VMI) protocols and minimizing supply discrepancies.}
%     \achievement{Improved decision-making processes by developing interactive dashboards with \tech{Plotly}, providing stakeholders with clear insights for strategic supply chain decision-making.}
% }

% \project{Python, SQL, KPI Identification}{Supply Chain Optimization through Data Analytics}{}{}{
%     \achievement{Led analysis of supply chain data, extracting key metrics to refine inventory management and inform data-centric marketing strategies.}
%     \achievement{Analyzed supplier performance to address inefficiencies, implementing solutions that bolstered supply chain resilience and led to a measurable decrease in defect rates.}
%     \achievement{Employed sophisticated data visualization methodologies to uncover and act upon trends within customer demographics and pricing strategies, driving improvements in logistical operations, and influencing cost-saving measures.}
% }

\section{Certification}
\project{Microsoft} {Career Essentials in Data Analysis}{}{}{}
\project{IBM}{Docker Essentials} {}{}

\end{document}